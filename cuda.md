# 《CUDA_Programming Guide 1.1中文版》笔记
## 第一章 CUDA介绍
Control, Cache, ALU, DRAM, Shared memory.
## 第二章 编程模型
- 线程批处理
```
Host, Device
Host write Kernel
Device assign Grid/Block/Thread
```

- 线程块Thread Block
```
1. 有共享内存

2. 同步。Kernel中指定的同步点， 在一个块里的线程会被挂起直到它们所有都到达同步点。

3. 线程ID， 是在块之内的线程编号。 根据线程ID可以帮助进行复杂的寻址。
3.1. 二维块 (Dx, Dy)， 线程的索引是(x, y)， 则线程ID=x+y Dx
3.2. 三位块(Dx, Dy, Dz), 线程的索引是(x, y, z)， 则线程ID=x+y Dx+z DxDy

4. 一个块可以包含的线程最大数量是有限的。
```

- 线程块栅栏Grid
```
1.线程协作的减少会造成性能损失，因为来自同一个栅格的不同线程块中的线程彼此之间不同通讯和同步。

2.块ID： 只有二维？(Dx, Dy), 块的索引是(x, y)， 则块ID=x+y Dx

```

- 内存模型: 数据读写
```
1. 读写每个线程的寄存器Register
2. 读写每个线程的本地内存 local memory
3. 读写每个块的共享内存 shared memory
4. 读写每个栅格的全局内存 global memory
5. 读每个栅格的常量内存 constant memory
6. 读每个栅格的纹理内存 texture memory
```

## 第三章 硬件实现

？？ 难点在于对warp的理解

- SIMD多处理器
```
1.设备
2.多处理器：包含很多个处理器
3.设备=多处理器的数组
4.每个多处理器使用SIMD架构，每个处理器执行同一指令，但操作不同的数据。
5.每个多处理器的内存模型：
5.1.每个处理器有一组本地32位寄存器
5.2.并行数据缓存或共享内存，被所有处理器共享，实现内存共享。
5.3.
```

- 执行模式
```
？？ 线程块在一个批处理中被一个多处理器执行，被称为active。 每个active块被划分称为SIMD线程组，称为warps（对应于栅格，每个warp对应于线程块，包括数量相同的线程，叫做warp大小）

每个线程可使用的寄存器数量 = 每个多处理器寄存器总数除以并发的线程数量。

这里的块跟线程块又有区别？

一个块内的warp次序是未定义的。

在一个线程块栅格内的块次序是未定义的，并且在块之间不存在同步机制，因此来自同一个栅格的二个不同块的线程不能通过全局内存彼此安全地通讯。
```

- 计算兼容性

- 多设备： 类型必须一样。

- 模式切换
```
primary surface
```
## 第四章 API

- 一个C语言的扩展
```
C语言扩展集
runtime
```

- 语言扩展
```
1. 函数类型限定句
__device__在设备上执行，仅可从设备调用
__global__声明一个函数作为一个存在的kernel。 在设备执行的，仅可从主机调用。
__host__ 在主机上执行，仅可从主机调用
__global__ __device__
  不支持递归
  不能声明静态变量
  ？？ 不能有自变量的一个变量数字
__device__
  不能取得函数地址
  函数指向__global__函数是支持的
不能一起使用__global__和__host__
__global__函数必须有void的返回类型。
任何调用到一个__global__函数必须指定它的执行配置。
？？ 对一个__global__函数的调用是同步的
__global__函数参数目前是通过共享内存到设备的，并且被限制在256字节。

2. 变量类型限定句
__device__声明驻留在设备上的一个变量， 全局内存空间，具有应用的生存期， 从栅格内所有线程和从主机通过runtime库是可访问的。
  以下与__device__一起使用：
    __constant__: 驻留在常量内存空间，具有应用的生存期，从栅格内所有线程和从主机通过runtime库是可访问的。
    __shared__ : 驻留在线程块的共享内存空间中，具有块的生存期，只有块之内的所有线程是可访问的。

3. 执行配置： 新的指令指定kernel如何在设备上执行
<<<Dg, Db, Ns, S>>>
Dg栅格维度 Dg.x, Dg.y
Db 块维度Db.x, Db.y, Db.z
Ns: 静态分配的内存之外的动态分配每个块的内存， 默认0，可选
S: Stream相关， 默认0， 可选


4. 内置变量指定栅格和块的维数， 还有块和线程的ID
gridDim: dim3 栅格维度
blockIdx: uint3 块索引
blockDim: dim3  块维度
threadIdx: uint3包含块之内的线程索引


5. nvcc编译 
__noinline__
行程计数 #pragma unroll 5
```

- 公共Runtime组件
```
可同时被Host和Device调用
1.内置矢量类型 float4, ...
2.dim3 = uint3
3.数学函数，看附录B
4.时间函数clock_t clock();
5.纹理类型， texture reference, texture fetch
```


## 第五章 性能指导

## 第六章 矩阵乘法的例子

## 附录A 技术规格
```
 一个块最大线程数是512；
 一个线程块在x-，y-，和z-空间的最大大小分别是512，512 ，和64；
 一个线程块栅格的每个最大空间大小是65535；
 Warp 的大小是32 个线程
 每个多处理器的寄存器数量是8192；
 每个多处理允许的共享内存大小是16KB，被分为16 个bank；
 常驻内存大小是64KB；
 每个多处理器常驻内存可用的缓存是8KB；
 每个多处理器纹理内存可用的缓存是8KB；
 每个多处理器最大可用的块数量是8；
 每个多处理器最大可用的warp 数量是24；
 每个多处理器最大可用的线程数是768；
 对于绑定到一维CUDA 数组的texture reference，最大宽度是2
13
15
 对于绑定到二维CUDA 数组的texture reference，最大宽度是2
16
，最大高度是2
 对于绑定到线性内存的texture reference ，最大宽度是2
27
 Kernel 大小限制为2 百万个原生指令集；
 每个多处理器由8 个处理器构成，因此每个多处理器可以在四个时钟周期内处理一个32 个线程的
warp。
```


## 附录B 数学函数

## 附录C 原子函数

## 附录D Runtime API 参考 page 91-136
