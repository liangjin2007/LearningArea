## 笔记

- autograd https://github.com/HIPS/autograd

- ensemble：集成多个预测模型[ensemble](https://github.com/liangjin2007/data_liangjin/blob/master/ensemble.jpg?raw=true)

- maximum likelihood： 使模型尽可能大地表达整个训练集 每个样本概率乘积product(p(s[i]))的最大化。 --> 取对数 --> 得到对数似然 log probability

- language model:
  - p(s) = p(w1,...,wT) = p(w1)p(w2 |w1)···p(wT |w1,...,wT−1)
  - Markov assumption
  - memoryless
  
  - NGram language model
    - conditional probability table
    - context length
    - data sparsity
    - distributed representation
  - Skip-Grams
  
- Guided Propagation

- maximum likelihood vs Bayesian method
  - Bayes p(D/theta)，observation和参数都是随机变量
  - 极大似然估计L(theta)=p(D), observation是随机变量，参数不是。



- Mixture Model






