# QA
- 1.位置编码有哪些？

```
固定位置编码：
正弦和余弦函数：在变换器模型中，最著名的做法是使用不同频率的正弦和余弦函数来编码位置信息。这种方法通过不同的频率来区分不同的位置，允许模型学习到序列的顺序关系。
独热编码：为序列中的每个位置分配一个唯一的二进制向量，但这种方法在长序列中可能效率不高。
可学习位置编码：
嵌入向量：为序列中的每个位置学习一个唯一的嵌入向量。这些向量在训练过程中与其他参数一起优化，使模型能够根据任务需求自适应地调整位置信息。
相对位置编码：
相对位置表示：与绝对位置编码不同，相对位置编码关注的是元素之间的相对位置关系。这种方法在某些任务中可以提供更丰富的位置信息。
旋转位置编码：
这是一种改进的位置编码方法，通过在自注意力计算中引入旋转因子，使模型能够更好地捕捉长距离依赖。
混合方法：
实际应用中，有时会结合以上几种方法，以适应特定任务的需求。
选择哪种位置编码方法取决于具体任务和模型架构。随着研究的深入，可能还会出现更多新的位置编码技术，以更好地服务于大型模型对序列位置信息的处理需求。
```


- 2. Transformer理解？
```
Transformer模型中的Q（Query）、K（Key）和V（Value）是自注意力机制（Self-Attention）中的三个核心概念。
它们是通过对输入的嵌入表示（例如，单词的嵌入向量）进行线性变换得到的。下面是对这三个组件的解释：
Q (Query)：
Query代表了当前要生成的目标位置的嵌入表示。在自注意力机制中，它被用来与所有的Key进行点积运算，以计算注意力权重。
换句话说，Query表示了“我当前正在处理的位置需要什么样的信息？”，它帮助模型确定在编码整个输入序列时，哪些部分对于当前的位置最为重要。
K (Key)：
Key代表了输入序列中所有位置的嵌入表示。它用于与Query进行点积运算，以确定每个位置的注意力权重。
Key可以被理解为“我（这个位置）可以为其他位置提供什么样的信息？”，它决定了当前序列中的每个位置对于其他位置的信息贡献。
V (Value)：
Value同样代表了输入序列中所有位置的嵌入表示。在计算了注意力权重之后，Value会被这些权重加权求和，以生成最终的输出表示。
Value包含了“我（这个位置）具体有什么信息？”，它是在自注意力机制中被查询（通过Query）和加权（通过注意力权重）的信息。
在Transformer中，Q、K和V是通过输入嵌入向量与三个不同的权重矩阵（W_q, W_k, W_v）进行线性变换得到的。这些权重矩阵是模型参数，通过训练得到。
自注意力机制的计算过程大致如下：
对于输入序列中的每个位置，使用W_q、W_k和W_v分别对嵌入向量进行线性变换，得到该位置的Q、K和V。
计算所有位置上的Q和所有位置上的K的点积，得到注意力得分。
将注意力得分除以一个缩放因子（通常是8或16，以避免内积过大导致的梯度消失问题）。
使用softmax函数对注意力得分进行归一化，得到注意力权重。
将注意力权重与对应的V进行加权求和，得到加权后的Value，即该位置的自注意力输出。
通过这种方式，自注意力机制允许每个位置的输出表示融合了输入序列中所有位置的信息，并且每个位置的贡献是根据其与当前Query的相关性动态调整的。
这是Transformer模型能够捕捉长距离依赖关系的关键机制。
```


- 3.视觉Transformer理解？
```
视觉Transformer（ViT）是一种基于Transformer架构的深度学习模型，专门用于处理视觉识别任务。
Transformer最初是为了处理序列到序列的任务（如机器翻译）而设计的，但后来其强大的特征提取和建模能力被成功迁移到图像领域。
以下是ViT的简要介绍：
核心思想：ViT将一幅图像分割成固定大小的图像块（例如16x16像素的块），并将这些块视为序列中的元素。
然后，这些图像块被线性嵌入为一个高维空间，并输入到标准的Transformer编码器中。
架构：ViT的主要部分是多层Transformer编码器，它包含自注意力机制和前馈神经网络。这种架构使得ViT能够捕捉图像块之间的复杂关系。
自注意力机制：允许模型在处理一个图像块时考虑到其他所有块的信息，这有助于捕捉图像中的长距离依赖关系。
位置编码：由于Transformer本身不具有处理序列中元素位置信息的能力，ViT通过为每个图像块添加位置编码来解决这个问题。
训练：ViT通常在大规模图像数据集上进行预训练，然后可以微调以适应特定任务，如图像分类、物体检测或分割。
优点：
灵活性：能够处理不同尺寸的输入图像，通过调整图像块大小和模型深度/宽度来适应不同的计算资源。
泛化能力：在多种视觉任务上表现出色，包括那些具有挑战性的任务。
可扩展性：由于其模块化的设计，ViT可以很容易地与其他类型的网络结构结合，以适应特定的应用需求。
缺点：
计算资源：对于非常大的模型和/或高分辨率图像，ViT可能需要大量的计算资源。
预训练需求：为了达到最佳性能，ViT通常需要在大规模数据集上进行预训练。
ViT的提出标志着计算机视觉领域的一个重要进展，它为如何利用Transformer架构处理视觉数据提供了新的视角，并启发了后续许多相关的研究工作。
```

- 4.Diffusion Model DDPM ， https://zhouyifan.net/2023/07/07/20230330-diffusion-model/
```
图片生成邻域里之前一般用GAN或者VAE来
```

- 5. https://zhuanlan.zhihu.com/p/643560888

